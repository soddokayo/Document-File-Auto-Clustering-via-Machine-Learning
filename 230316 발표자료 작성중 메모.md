# 찾아보고 더할 자료

- [텍스트 분류모델 ](https://huggingface.co/models?pipeline_tag=text-classification)
- [nltk tokenization before TFIDF](https://www.bogotobogo.com/python/NLTK/tf_idf_with_scikit-learn_NLTK.php)
- [BERT의 768 아웃풋에 대한 단서](https://heekangpark.github.io/nlp/huggingface-bert)
- [768 아웃풋 보는 법 2](https://huggingface.co/bert-base-uncased#how-to-use)
- [닥치고 HuggingFace Transformers 공식문서만 읽어도 이해할듯](https://wikidocs.net/166796)
